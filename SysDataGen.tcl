#//##########################################################################################################################
# Script Name   SysDataGen.tcl
# @author       Anna Devore
# @since        April 18,2001
# Platform      Unix or NT.
# Purpose       Uses the above named files to generate a DML to update system data at site and
#                a report summarizing all differences between model and site system data.
#
# Usage:    mtclsh SysDataGen.tcl <System Data Model Files directory> <Target database connect string> [Report/DML directory]
#
# Description:
#   Include a model files directory, site or target db logon string and
#       a directory where the resulting DMLs and report will be placed.
#
#
# MODIFICATION LOG
# Who   When        Comments
# ---   ----------  ----------------------------------
# JRW   03/30/2015  570229 - created getNextSequence and implemented down wherever there was an [open fileName_$seq w] call
#
#//##########################################################################################################################
global sdgInfo
global modifiedTables

if {[catch {getInfo _common_utilities_loaded}]} {
    if [catch {glob common_utilities.tcl} err] {
        puts "The file common_utilities.tcl is not in the current directory."
        puts "This script cannot run without it."
        puts "Please obtain this file and copy it into this directory."

        return 2
    } else {
        puts "Sourcing common_utilities.tcl..."
        source common_utilities.tcl
    }
}

# set up debugging, if required
if {([info exists ::env(_DEBUG)] && $::env(_DEBUG) == "true") || ([info exists _SDG_DEBUG] && $_SDG_DEBUG == "true")} {
    set sdgInfo(_SDG_DEBUG) "true" ;# ensure local val is set
} else {
    set sdgInfo(_SDG_DEBUG) "false"
}


proc SysDataGen.version {} {return "5.0"}
proc SysDataGen.revision {} {return "1.1"}


# ############################ deleteScriptHeader
# Creates the header for the delete sql script
# @author RE
# @param names_file names file used in validation
# @param values_file values  file used in validation
# @param where_file where file used in validation
# @param spool spool file name
# @return header string
proc deleteScriptHeader {names_file values_file where_file spool} {
    global sdgInfo

    set     del_can ""

    lappend del_can "/*"
    lappend del_can "  EXL Healthcare System Data Delete Script "
    lappend del_can "  $sdgInfo(date_stamp)"
    lappend del_can " "
    lappend del_can "  Database: $sdgInfo(database)"
    lappend del_can "  Generated from: $names_file, $values_file, and $where_file."
    lappend del_can "  =========================================================="
    lappend del_can "  This DML was generated by SysDataGen.tcl version [SysDataGen.version], revision [SysDataGen.revision].\n"
    lappend del_can "  The data identified in the SQL SELECT statements "
    lappend del_can "  will be deleted as it is not valid system data."
    lappend del_can ""
    lappend del_can "[getInfo SupportContact]"
    lappend del_can "*/\n"
    lappend del_can "spool $spool"
    lappend del_can "set scan off"
    lappend del_can "set echo on"
    lappend del_can "/************************************"
    lappend del_can "Confirm that the last SQL script"
    lappend del_can "ran to completion. Error out if it"
    lappend del_can "did not."
    lappend del_can "************************************/"
    lappend del_can "select to_date('ERROR: A script did not complete successfully. Contact EXL Healthcare Support.') from dual where exists"
    lappend del_can "(SELECT    SHS_SQL_SCRIPT_NAME"
    lappend del_can "FROM   SHS_SCHEMA_HISTORY"
    lappend del_can "WHERE  SHS_UID = ( SELECT MAX (SHS_UID) FROM SHS_SCHEMA_HISTORY WHERE SHS_TYPE = 'UPDATE')"
    lappend del_can "AND    SHS_RESULTS <> 'Successful');"
    lappend del_can "/************************************"
    lappend del_can "Insert a starting-point record into SHS."
    lappend del_can "************************************/"

    return [join $del_can \n]
}


# ############################ reportHeader
# Creates the header for the report file
# @author RE
# @param names_file names file used in validation
# @param values_file values file used in validation
# @param where_file where file used in validation
# @return header string
proc reportHeader {names_file values_file where_file} {
    global sdgInfo

    set report ""

    lappend report "The differences in this report were created by comparing:"
    lappend report "$names_file, $values_file, and $where_file"
    lappend report "with $sdgInfo(database)."
    lappend report ""
    lappend report "Generated $sdgInfo(date_stamp) using SysDataGen.tcl version [SysDataGen.version], revision [SysDataGen.revision].\n "
    lappend report ""

    return [join $report \n]
}


# ############################ DMLheader
# Creates the header for the insert/update sql script
# @author RE
# @param names_file names file used in validation
# @param values_file values file used in validation
# @param where_file where file used in validation
# @return header string
proc DMLheader {names_file values_file where_file spool AutoScript} {
    global sdgInfo

    set DML ""

    lappend DML "/*"
    lappend DML "  EXL Healthcare System Data Modification Script "
    lappend DML "  $sdgInfo(date_stamp)"
    lappend DML ""
    lappend DML "  Database: $sdgInfo(database)"
    lappend DML "  Generated from: $names_file, $values_file, and $where_file"
    lappend DML "  =========================================================="
    lappend DML "  This DML was generated by SysDataGen.tcl version [SysDataGen.version], revision [SysDataGen.revision]"
    lappend DML "  to update system data."
    lappend DML ""
    lappend DML "[getInfo SupportContact]"
    lappend DML "*/"
    lappend DML ""
    lappend DML "spool $spool"
    if {$AutoScript == "no" } {
        lappend DML "whenever sqlerror exit 1"
    }
    lappend DML "set scan off"
    lappend DML "set echo on"
    lappend DML "/************************************"
    lappend DML "Confirm that the last SQL script"
    lappend DML "ran to completion. Error out if it"
    lappend DML "did not."
    lappend DML "************************************/"
    lappend DML "select to_date('ERROR: A script did not complete successfully. Contact EXL Healthcare Support.') from dual where exists"
    lappend DML "(SELECT    SHS_SQL_SCRIPT_NAME"
    lappend DML "FROM   SHS_SCHEMA_HISTORY"
    lappend DML "WHERE  SHS_UID = ( SELECT MAX (SHS_UID) FROM SHS_SCHEMA_HISTORY WHERE SHS_TYPE = 'UPDATE')"
    lappend DML "AND    SHS_RESULTS <> 'Successful');"
    lappend DML "/************************************"
    lappend DML "Insert a starting-point record into SHS."
    lappend DML "************************************/"

    return [join $DML \n]
}


# ############################ sdg_report
# outputs to the sysdatagen log file, including breaks for new pages.
# @author LAQ
# @param line_out - string output with new lines for breaks.
# @return 0
# @globals array sdgInfo
# @see nextPage
proc sdg_report {line_out {fid ""}} {
    global sdgInfo
    if {$fid == ""} {
        set fid [getInfo default_channel]
    }

    set lines [split $line_out \n]

    foreach line $lines {
        if { $sdgInfo(line_count) > $sdgInfo(maxLines) } {
            puts $fid [nextPage]
            puts $fid "\n$sdgInfo(currentHeader)\n"

            incr sdgInfo(line_count) 3
        }
        puts $fid $line
        incr sdgInfo(line_count)
    }

    return $sdgInfo(line_count)
}


# ############################ sdg_list_report
# helper function for sdg_report
# @author LAQ
# @param list out - list of strings to output
# @return none really, global
# @see sdg_report
proc sdg_list_report {list_out {fid ""} } {
    return [sdg_report [join $list_out \n] $fid]
}


# ############################ deleteScriptHeader
# proc to imitate value of -all param for older tcl versions
# if -all is valid, uses that
# @author LAQ
# @param lst list of values
# @param token search for token in value list * for all
# @return indices of list that match
proc lsearchall {lst token} {
    set indices ""

    if [catch {lsearch -all $lst $token} indices ] {
        set indices ""
        for {set i 0} {$i < [llength $lst]} {incr i} {
            if {[lsearch [lindex $lst $i] $token] >= 0} {
                lappend indices $i
            }
        }
    }

    return $indices
}


# splits a string on a mulit-character token
# @author laq
# @param str string to split
# @param splitStr character to find to split on
# @param mc temp char to use to split with - default null char (0)
# @return list of string segments
proc strsplitA {str splitStr {mc {\xFFFF}}} {
    if {[regexp $mc $str b]} {
        #puts "found b $b"
    }

    return [split [string map [list $splitStr $mc] $str] $mc]
}


proc getConcatVals {str splitStr} {
    set Vals ""
    _SDG_PUTT $str
    set str [string trimleft [string trimright $str \}] \{]
    _SDG_PUTT "str now $str"
    set len [string length $splitStr]

    while {1} {
        set i [string first $splitStr $str]

        if {$i < 0} {
            _SDG_PUTT ":end? $str"
            _SDG_PUTT "$splitStr"
            lappend Vals $str

            break
        } else {
            set end [expr $i + $len]
            incr i -1
        }

        set val [string range $str 0 $i]
        _SDG_PUTT "val322=$val"
        set str [string range $str $end end]
        lappend Vals $val
    }

    _SDG_PUTT "$Vals"

    return $Vals
}


proc strSplitD {str splitStr} {
    if [regsub "^$splitStr" $str "" str] {
        _SDG_PUTT $str
        exit
    }

    while {[string length $str] > 0} {
        regexp "^(^$splitStr)*($splitStr)" $str all val token
        regsub ^$all $str "" str
        if {$token != $splitStr} {
            _SDG_PUTT "error? $str"
            lappend Vals $str
        }
    }
}


# ############################ cleanModelVals
# takes raw values from model or schema that are concatenated with !!! and
# turns them into a string.
# side effect - also subs single ' with '' for query and inserts
# @author RE
# @param modstring concatenated values
# @return list of values
proc cleanModelVals {modstring db_delimit} {
    # replace interior join single quotes
    regsub -all {`} $modstring "'" modstring
    #escape single quotes
    regsub -all {'} $modstring "''" modstring
    return [getConcatVals $modstring "$db_delimit" ]
}


# ############################ getNextSequence
# Returns the global File Sequence Number (Info Array)
# If it has not been set already, then it is set to 1
# @author RE
# @param  sequenceName sequence array key for each file
# @return The next File Sequence Number
proc getNextSequence {sequenceName} {
    if {[set currentValue [getInfo $sequenceName]] == ""} {
        set currentValue 0
        setInfo $sequenceName $currentValue
    }
    incr currentValue
    updateInfo $sequenceName $currentValue
    return $currentValue
}


# ############################ getUniqueConstraints
# takes raw values from model or schema that are concatenated with !!! and
# turns them into a string.
# side effect - also subs single ' with '' for query and inserts
# @author RE
# @param dbh database connection handle
# @param table database table name
# @param key_lst primary key columns
# @param col_lst list of columns to check
# @return list of list made of columns with unique constraint, list of what position in original column list.
# Not sure why it returns the index - i suppose you could use it instead of the column name.
proc getUniqueConstraints {dbh table key_lst col_lst} {
    set checkit {}
    set SQL_Statement  "select  constraint_name, column_name
                        into    :constraint_lst, :cons_columns
                        from    user_cons_columns
                        where   table_name = '$table'
                        and     constraint_name like '%UNIQUE%'"
    catch {execsql use $dbh $SQL_Statement} code

    if {$code != 100 && $constraint_lst != {}} {
        foreach col $cons_columns {
            set ci [lsearch $col_lst $col]
            if {$ci >= 0} {
                lappend cols $col
                lappend index_lst $ci
            }
        }

        # see if uniques are already covered entirely by key list
        foreach col $cols {
            if {[lsearch $key_lst $col] < 0} {
                set checkit 1
                break
            }
        }
    }

    if {$checkit == 1} {
        set checkit [list $cols $index_lst]
    }
    return $checkit
}


# ############################ checkUnique
# determines if missing key value items are truly missing, or exist
# with the wrong UID/ key value
# discriminates between inserts, maps and moves each handled differently
# @author LAQ
# @param dbh database connection handle
# @param table table being compared
# @param key_lst list of key columns
# @param column_lst list of rest of columns
# @param value_lst list of values from schema
# @return  list including okInserts (insertable items) moverows (items that can have key reset)
# @return collisions (items that need fk mapping) moveVals (values) collisionVals (values)
# @return moveOldVals (old incorrect key values)
proc checkUniqueRow {dbh table key_lst column_lst rowdata db_delimit meta1} {
    set col_lst             [concat $key_lst $column_lst]
    set okInserts           ""
    set moverows            ""
    set collisions          ""
    set moveVals            ""
    set moveOldVals         ""
    set collisionVals       ""
    set collisionOldVals    ""
    if {$meta1 == 0} {
        set meta1 [getUniqueConstraints $dbh $table $key_lst $col_lst]
    }
    # uniques exists outside of key list
    if {$meta1 != {}} {
        set cols [lindex $meta1 0]
        set index_lst [lindex $meta1 1]
        # get any foreign keys constraint this table - for use later, but outside of loop
        set sql    "select  count(*)
                    into    :fcons
                    from    USER_CONSTRAINTS
                    where   r_constraint_name in   (select  constraint_name
                                                    from    user_constraints
                                                    where   table_name = '$table'
                                                    and     constraint_type = 'P')"
        execsql use $dbh $sql
        # now determine how to handle individual values
            # generate select based on unique constraint column values
        set t ""
        foreach c $cols index $index_lst {
            lappend t "$c = '[lindex $rowdata $index]'"
        }

        set SQL    "select  [join $key_lst "||'$db_delimit'||"]
                    into    :pkcol
                    from    $table
                    where   [join $t " and "]"
        _SDG_PUTT $SQL
        execsql use $dbh $SQL
        # does any value match the unique constraints?
        if {$pkcol == {}} {
            # no
            set okInserts 1
        } else {
            if {$fcons == 0} {
                # yes, but
                # no fk exists on this column, ok to move uid
                set moverows 1
                set moveVals "$t"
                set moveOldVals $pkcol
            } else {
                # yes, and fk's constrain us
                if {[llength $key_lst] > 1} {
                    error "Cant do this : $table $key_lst"
                } else {
                    set collisions 1
                    set collisionVals ${t}
                    set collisionOldVals $pkcol
                }
            }
        }
    } else {
        set okInserts 1
    }

    return [list $okInserts $moverows $collisions $moveVals $collisionVals $moveOldVals $collisionOldVals $meta1]
}


# ############################ doMoves
# creates SQL for moving records to new key values
# @author LAQ
# @param table_name database table
# @param key_name_lst primary key columns
# @param column_name_lst rest of columns in definition - not used??
# @param inserts all system data rows that were not found (used for correct pk values)
# @param moveRows indexes of the inserts list that need to be moved (to find correct pk values)
# @param moveVals the incorrect pk value in the client schema
# @return list of sql statements
# @see checkUnique
proc doMoves {table_name key_name_lst column_name_lst inserts moveRows moveVals} {
    global sdgInfo

    set moveSQL_lst     ""
    set pre             [string range $table_name 0 2]
    set SQL_Statement   "update $table_name set\n"
    set counter         0
    set currentData     ""

    foreach rowData $moveRows {
        set currentData     [lindex $moveVals $counter]
        set keystatement    ""
        set i               0
        foreach key $key_name_lst {
            lappend keystatement "$key = '[lindex $rowData $i]'"
            incr i
        }

        if {$sdgInfo(auditColumns) == "true"} {
            lappend keystatement "$pre\_USR_UID_UPDATED_BY = -4"
            lappend keystatement "$pre\_LAST_UPDATE_DATE = sysdate"
        }

        incr counter

        lappend moveSQL_lst "$SQL_Statement \t[join $keystatement ",\n\t"]\nwhere\n\t[join $currentData " and "];"
    }

    return $moveSQL_lst
}


# ############################ doInserts
# Generates SQL to insert new rows
# @author LAQ
# @param dbh database connection handle
# @param table schema table name
# @param key_name_lst list of pk columns
# @param column_name_lst rest of the columns
# @param insertData data to insert
# @param insertRows indexes of insert data to insert
# @return list of SQL statements
proc doInserts {dbh table key_name_lst column_name_lst insertData}  {
    global sdgInfo
    global modifiedTables
    set insertSQL_lst ""
    set disable_lst ""
    set enable_lst ""
    set pre [string range $table 0 2]

    foreach rowData $insertData {
        if {[llength $column_name_lst] > 0} {
            set insert_sql "insert into $table (\n\t[join $key_name_lst ",\n\t"],\n\t[join $column_name_lst ",\n\t"]"
        } else {
            set insert_sql "insert into $table (\n\t[join $key_name_lst ",\n\t"]"
        }
        if {$sdgInfo(auditColumns) == "true"} {
            append insert_sql ",\n\t$pre\_USR_UID_CREATED_BY,\n\t$pre\_CREATE_DATE"
        }
        append insert_sql "\n) values (\n"

        if {[llength $rowData] != [expr [llength $column_name_lst] + [llength $key_name_lst]]} {
            _SDG_PUTT "DIFF: row = $rowData"
            _SDG_PUTT "column = $column_name_lst $key_name_lst"
        }
        append insert_sql "\t[joinSQL $rowData ",\n\t"]"

        if {$sdgInfo(auditColumns) == "true"} {
            append insert_sql ",\n\t-4,\n\tsysdate"
        }

        append insert_sql "\n);\n\n"
        lappend insertSQL_lst $insert_sql
    }
    # disable self referential constraints.
    set sql    "select      constraint_name, table_name
                into        :fkNames, :fkTables
                from        USER_CONSTRAINTS where r_constraint_name in    (select  constraint_name
                                                                            from    user_constraints
                                                                            where   table_name = '$table'
                                                                            and     constraint_type = 'P')
                and         table_name = '$table'
                order by    constraint_name"
    execsql $sql

    foreach fkName $fkNames fkTable $fkTables {
        lappend disable_lst "Alter table $fkTable disable constraint $fkName;"
        lappend enable_lst "Alter table $fkTable enable constraint $fkName;"
    }
    return [list $insertSQL_lst $disable_lst $enable_lst]
}


# ############################ joinSQL
# Generates SQL to insert new rows
# @author LAQ
# @param data values
# @param joiner token to join items with
# @return token joined single quoted values (eg 'hi','by')
# @see quoteSQL
proc joinSQL {data joiner} {
    set sql ""

    foreach datum $data {
        lappend sql [quoteSQL $datum]
    }

    return [join $sql $joiner]
}


# ############################ quoteSQL
# Generates quoted items as long as not oracle literals (eg chr(20))
# @author LAQ
# @param datum value
# @return  single quoted values (eg 'hi') or literal as is
# @see joinSQL
proc quoteSQL {datum} {
    if {[string range $datum 0 3] != "chr("} {
        set datum '$datum
    }

    if {![regexp {chr\(\d\d\)$} $datum]} {
        append datum '
    }

    return $datum
}


# ############################ lgetThese
# returns list of list elements described in index list
# @author LAQ
# @param thelist list of values
# @param theindices list of indexes
# @return list including only those indices in indices list from original list
proc lgetThese {thelist theindices} {
    set outlist ""

    foreach i $theindices {
        lappend outlist [lindex $thelist $i]
    }

    return $outlist
}


# ############################ doMaps
# Creates SQL for items that need to be moved to new UID/key value and
# have other tables that need to point to that new value
# @author LAQ
# @param dbh database connection handle
# @param table_name database table name
# @param key_name_lst list of pk columns
# @param column_name_lst rest of columns in definition
# @param inserts list of all items not in schema
# @param mapRows indexes to inserts list of itesm that need to be mapped instead of inserted
# @param mapVals not used?
# @param oldPKs old pk values that will be updated to correct system values
# @return SQL statements, including fk disable and enable statements
# as well as sql to update row and ancillary table key values
proc doMaps {dbh table_name key_name_lst column_name_lst inserts mapRows mapVals oldPKs} {
    global sdgInfo
    global modifiedTables

    set mapSQL_lst  ""
    set disable_lst ""
    set enable_lst  ""
    set update_lst  ""
    set insertVals  ""
    set oldVals     $mapVals ;# these are the unique constraint values
    set pre         [string range $table_name 0 2]
    set keylen      [llength $key_name_lst]
    if {$keylen > 1} {
        error "cannot do this yet"
    }
    set keycol [lindex $key_name_lst 0]
    foreach insertVal $mapRows oldVal $oldVals {
        set sql "Update $table_name set
    $keycol = '$insertVal'"
        if {$sdgInfo(auditColumns) == "true"} {
            append sql ",
    $pre\_USR_UID_UPDATED_BY = -4,
    $pre\_LAST_UPDATE_DATE = sysdate"
        }
        lappend update_lst "$sql
where
    [join ${oldVal} " and "];"
    }

    lappend update_lst "COMMIT;"
    set sql    "select      constraint_name, table_name
                into        :fkNames, :fkTables
                from        USER_CONSTRAINTS
                where       r_constraint_name in (select  constraint_name
                                                from    user_constraints
                                                where   table_name = '$table_name'
                                                and     constraint_type = 'P')
                order by    constraint_name"
    execsql $sql

    foreach fkName $fkNames fkTable $fkTables {
        lappend disable_lst "Alter table $fkTable disable constraint $fkName;"

        set sql    "select      column_name
                    into        :fkcols
                    from        user_cons_columns
                    where       constraint_name = '$fkName'
                    order by    column_name"
        _SDG_PUTT $sql
        execsql $sql

        foreach fkcol $fkcols {
            foreach insertVal $mapRows oldVal $oldVals oldpk $oldPKs  {
                lappend update_lst "Update $fkTable set $fkcol = '$insertVal' where $fkcol = '$oldpk';"
                lappend modifiedTables "$fkTable,$fkcol,$insertVal,$oldpk"
            }
            lappend update_lst "COMMIT;"
            lappend enable_lst "Alter table $fkTable enable constraint $fkName;"
        }
    }

    return "[join $disable_lst \n]\n[join $update_lst \n]\nCOMMIT;\n[join $enable_lst \n]\n"
}

# ############################ captureDiffs
# determines which columns in "update" row (one per call) that need updating
# @author LAQ
# @param modelValues correct values
# @param schemaValues values from schema to compare
# @param columnList list of column names
# @see reallyDiff
# @return list of diffs only - {column name, schema value, model value} for the row
proc captureDiffs {modelValues schemaValues columnList} {
    set schemaDiffs ""

    foreach modelValue $modelValues schemaValue $schemaValues column $columnList {
        set md "$modelValue"
        set tmp_data $schemaValue
        # to handle carriage returns and line feeds in data, we need to translate them to
        # chr(xx) values, as we did when creating the model files.
        # TO DO: the translation of the \n may be system or db setting dependent.
        if {[regexp {(\|\|chr\(\d\d\))|(chr\(\d\d\)\|\|)} $md]} {
            regsub -all {(\r[\n\f])} $tmp_data "`||chr(13)||chr(10)||`" tmp_data
            regsub -all {\r} $tmp_data "`||chr(13)||`" tmp_data
            regsub -all {[\n\f]} $tmp_data "`||chr(10)||`" tmp_data
            regsub -all {\)\|\|``\|\|c} $tmp_data ")||c" tmp_data
            regsub -all {`} $tmp_data "'" tmp_data
            regsub -all {^'\|\||\|\|'$} $tmp_data "" tmp_data
        }

        if [reallyDiff $tmp_data $md] {
            lappend schemaDiffs [list $column $tmp_data $modelValue]
            _SDG_PUTT "md    =$md*"
            _SDG_PUTT "modval=$modelValue*"
        }
    }

    return $schemaDiffs
}


# ############################ reallyDiff
# Determines if a diff is real or a false positive based on character encoding
# may be depricated if encoding is standardized or special characters are disallowed.
# @author LAQ
# @param curr_entry schema value
# @param value model value
# @return 1=diff 0=false diff
proc reallyDiff {curr_entry value} {
    # code added to allow utf-8 characters that were showing up incorrectly.
    set reallydif 0
    set c -1
    set v -1
    set curr_lst [split $curr_entry ""]
    set value_lst [split $value ""]

    # if lengths the same, then have to do character by character to trap encoding diffs.
    if {[llength $curr_lst] == [llength $value_lst]} {
        foreach c $curr_lst v $value_lst {
            if {$c != $v} {
                scan $c %c dbchar
                scan $v %c modelchar

                #seems some db encoding is reading copyright char as utf 16, with 1111111 prefixed instead of 00000000
                if {$dbchar > 65280} {
                    set dbchar [expr $dbchar - 65280]
                }
                if {$dbchar != $modelchar } {
                    set reallydif 1
                    break
                }
            }
        }
    } else {set reallydif 1}

    return $reallydif
}


# ############################ doUpdates
# Creates SQL for update statements
# @author LAQ
# @param table_name database table
# @param updates list of items for rows that need updating
# @param key_name_lst pk list to be able update correct record.
# @return list of SQL statements
proc doUpdates {table_name updates key_name_lst} {
    global sdgInfo
    set sql_lst ""
    set pre     [string range $table_name 0 2]

    foreach line $updates {
        set keyvals [lindex $line 0]
        set colvals [lindex $line 1]
        set sql     ""
        set t       ""
        set k       ""

        foreach val $colvals {
            lappend t "[lindex $val 0] = [quoteSQL [lindex $val 2]]"
        }

        foreach val $keyvals key $key_name_lst {
            lappend k "$key = '$val'"
        }

        set sql "update $table_name set\n\t[join $t ",\n\t"]"
        if {$sdgInfo(auditColumns) == "true"} {
            append sql ",\n\t$pre\_USR_UID_UPDATED_BY = -4,\n\t$pre\_LAST_UPDATE_DATE = sysdate"
        }

        lappend sql_lst "$sql\nwhere\n\t[join $k " and "];"
    }

    return $sql_lst
}


# ############################ doDeletes
# Creates SQL for "select" and delete statements
# Alternately, if systemYN can be set to N, it will do that.
# @author LAQ
# @param table_name database table
# @param deletes list of rows that need deleting
# @param key_name_lst pk list to be able delete the correct record.
# @return list of SQL statements
proc doDeletes {table_name deletes key_name_lst where_clause} {
    set sql_lst     ""
    set selectStat  "select * from $table_name where"

    foreach delrow $deletes {
        set deleteStat "delete from $table_name where"
        if {[regexp -nocase {and[\s]*SYSTEM_YN.*=.*'Y'} $where_clause]} {
            # this needed if yn flag is only part of where clause, (joined with and/or) in which case
            # we should check the other column value, but for now set to N
            # so this is a TODO based on does this condition ever occur
            set deleteStat "Update $table_name set [string range $table_name 0 2]_SYSTEM_YN = 'N' where"
        } elseif [regexp {SYSTEM_YN.*=.*'Y'} $where_clause] {
            # TO date, system yn flags are all XXX_SYSTEM_YN
            set deleteStat "Update $table_name set [string range $table_name 0 2]_SYSTEM_YN = 'N' where"
        }

        set wherecondition ""
        set delvals $delrow

        for {set i 0} {$i < [llength $key_name_lst]} {incr i} {
            lappend wherecondition "[lindex $key_name_lst $i] = '[lindex $delvals $i]'"
        }

        if {$wherecondition != ""} {
            set wherecondition [join $wherecondition " and "]
        }

        lappend sql_lst "$selectStat\n$wherecondition;"
        lappend sql_lst "$deleteStat\n$wherecondition;"
    }

    return $sql_lst
}


# ############################ splitDMLtoSize
# splits sql lines to no more that 100 chars per line
# @author RE
# @param DML_entry sql statemtent
# @return sql split into lines of at most 100 chars.
proc splitDMLtoSize {DML_entry} {
    while { [string length $DML_entry] > 100 } {
        set i_value [string first ") values (" $DML_entry]
        if { $i_value < 0 } {
            set i_c [string first "','" [string range $DML_entry 50 end]]
            if {$i_c < 0 } {
                set i_c [string first ",null" [string range $DML_entry 50 end]]
                if {$i_c < 0 } {
                    set i_c [string length $DML_entry]
                } else {
                    incr i_c 50
                }
            } else {
                set i_c_q [string first "'',''" [string range $DML_entry 50 end]]
                if { [expr $i_c - $i_c_q ] == 1 } {
                    set i_c [string length $DML_entry]
                }
                incr i_c 51
            }

            set seg_out [string range $DML_entry 0 $i_c]
            incr i_c
        } else {
            if { $i_value > 100 } {
                set i_c [string first "," [string range $DML_entry 50 end]]
                incr i_c 50
                set seg_out [string range $DML_entry 0 $i_c]
            } else {
                set i_c $i_value
                incr i_c 8
                set seg_out [string range $DML_entry 0 $i_c]
            }

            incr i_c
        }

        lappend t_DML "\t$seg_out"
        set DML_entry [string range $DML_entry $i_c end]
    }
    return [join $t_DML \n]
}


# ############################ getWhereClauses
# gets the where clause from the where file for queries.
# if the where clause includes an "in" clause, we do not
# validate against what is in the values table rather than
# utilize the where clause. (DVT 558507)
# @author LAQ
# @param where_source source file handle
# @return two joined lists - tablenames and where clauses.
proc getWhereClauses {where_source} {
    set where_id_lst        "> . in ( ) = or and < , ' "
    set firstLoop           "true"
    set where_clause        ""
    set where_table_lst     [list]
    set where_clause_lst    [list]

    while { ! [eof $where_source] } {
        gets $where_source eval_string

        set string_type F

        foreach op $where_id_lst {
            if { [string first $op $eval_string] >= 0 } {
                set string_type W
            }
        }

        if { $string_type == "F" } {
                lappend where_table_lst $eval_string
                # if this is the first time through the while loop, we have no where clause yet
                if {!$firstLoop} {lappend where_clause_lst $where_clause}
                set where_clause ""
                # now that we are past testing for the first iteration of this loop, set firstLoop to false
                if {$firstLoop} {set firstLoop false}
        } else {
            append where_clause $eval_string
        }
    }

    lappend where_clause_lst $where_clause

    return [list $where_table_lst $where_clause_lst]
}


# ############################ keysToAdd
# Ouputs changes to the log file
# @author LAQ
# @param report output handle
# @param table_name database table
# @param key_names key columns (pk)
# @param modvals model values
# @param valuesList current client values
# @param {action "Added"} type of action (not implemented )
# @see sdg_report
# @see sdg_list_report
# @return none
proc keysToAdd {report table_name key_names new_key_lst {action "Added"}} {
    global sdgInfo

    set sdgInfo(currentHeader)  " - SYSTEM DATA INSERTS FOR $table_name.  Key(s) are $key_names."
    set line_count              $sdgInfo(line_count)
    set key_names               [join $key_names ","]
    set output                  ""

    sdg_report "\n$sdgInfo(currentHeader)\n" $report

    regsub -all {''} $new_key_lst "'" new_key_lst

    foreach key $new_key_lst {
            lappend output " [join $key ", "]"
    }; #end of processing keys.

    sdg_list_report $output $report
}


# ############################ keysToUpdate
# Ouputs changes to the log file
# @author LAQ
# @param report output handle
# @param table_name database table
# @param key_names key columns (pk)
# @param modvals model values
# @param valuesList current client values
# @param {action "Updated"} type of action (not implemented )
# @see sdg_report
# @see sdg_list_report
# @return none
proc keysToUpdate {report table_name key_names valuesList {action "Updated"}} {
    global sdgInfo

    set sdgInfo(currentHeader)  " - SYSTEM DATA UPDATES FOR $table_name.  Key(s) are $key_names."
    set key_names               [join $key_names ","]
    set output                  ""

    sdg_report "\n$sdgInfo(currentHeader)\n" $report

    regsub -all {''} $valuesList "'" valuesList

    foreach line $valuesList {
        set keyVal [lindex $line 0]

        foreach item [lindex $line 1] {
            lappend output "  Key: [join $keyVal ", "]    Column: [lindex $item 0]"
            set is [lindex $item 1]
            set sb [lindex $item 2]
            if {$is == ""} {set is NULL}
            if {$sb == ""} {set sb NULL}
            lappend output "    IS  -> \"$is\""
            lappend output "    S/B -> \"$sb\""
            lappend output ""
        }
    }

    sdg_list_report $output  $report
}


# ############################ keysToMove
# Ouputs changes to the log file
# @author LAQ
# @param report output handle
# @param table_name database table
# @param key_names key columns (pk)
# @param modvals model values
# @param valuesList current client values
# @param {action "Moved"} type of action (not implemented )
# @see sdg_report
# @see sdg_list_report
# @return none
proc keysToMove {report table_name key_names modvals valuesList {action "Moved"}} {
    global sdgInfo

    set sdgInfo(currentHeader)  " - SYSTEM DATA KEY MOVES FOR $table_name.  Key(s) are $key_names."
    set key_names               [join $key_names ","]
    set moves                   ""

    sdg_report "\n$sdgInfo(currentHeader)\n" $report

    regsub -all {''} $valuesList "'" valuesList
    regsub -all {''} $modvals "'" modvals

    foreach modval $modvals val $valuesList {
        lappend moves "  Column: $key_names"
        lappend moves "    IS  -> $val"
        lappend moves "    S/B -> $modval"
        lappend moves ""
    }

    sdg_list_report $moves $report
}


# ############################ keysToMap
# outputs changes to log file
# @author LAQ
# @param report output handle
# @param table_name database table
# @param key_names key columns (pk)
# @param modvals model values
# @param valuesList current client values
# @param {action "Mapped"} type of action (not implemented )
# @see sdg_report
# @see sdg_list_report
# @return none
proc keysToMap {report table_name key_names modvals valuesList {action "Mapped"}} {
    global sdgInfo
    global modifiedTables

    set sdgInfo(currentHeader)  " - SYSTEM DATA KEY MAPPING FOR $table_name.  Key(s) are $key_names."
    set key_names               [join $key_names ","]
    set output                  ""

    sdg_report "\n$sdgInfo(currentHeader)\n" $report

    regsub -all {''} $valuesList "'" valuesList
    regsub -all {''} $modvals "'" modvals

    foreach modval $modvals val $valuesList {
        lappend output "  Column: $key_names"
        lappend output "    IS  -> $val"
        lappend output "    S/B -> $modval"
        lappend output ""
    }
    sdg_list_report $output $report
    lappend modifiedTables "$table_name,$key_names,$modvals,$valuesList"
}


# ############################ keysToMapCollision
# outputs changes to log file
# @author MOHIT UNIYAL
# @param report output handle
# @param table_name database table
# @param key_names key columns (pk)
# @see sdg_report
# @see sdg_list_report
# @return none
proc keysToMapCollision {report table_name key_names} {
    global sdgInfo
    global modifiedTables
    if {[catch {set len [llength $modifiedTables]} ]} {
        return 0
    }

    set modTabTemp [lsearch -all -inline $modifiedTables "$table_name*"]
    if {[catch {set len [llength $modTabTemp]} ]} {
        return 0
    }
    if {$len > 0} {
        set sdgInfo(currentHeader)  " - SYSTEM DATA KEY MAPPING FOR $table_name.  Key(s) are $key_names."
        set key_names               [join $key_names ","]
        set output                  ""
        sdg_report "\n$sdgInfo(currentHeader)\n" $report
        foreach element $modTabTemp {
            set vals        [split $element ","]
            lappend output "  Column:  [lindex $vals 1]"
            lappend output "    IS  -> [lindex $vals 3]"
            lappend output "    S/B -> [lindex $vals 2]"
            lappend output ""
        }
        sdg_list_report $output $report
    }
}

# ############################ outputWithCommits
# Creates SQL including commits per commitcount
# @author LAQ
# @param statements list of sql statments
# @param commitcount how frequently to commit (default 100)
# @return SLQ script
proc outputWithCommits {statements {commitcount 100}} {
    set i   0
    set sql ""

    foreach statement $statements {
        incr i
        append sql $statement\n

        if {$i >= $commitcount} {
            append sql "\nCOMMIT;\n\n"
            set i 0
        }
    }

    if {$i != 0} {
        append sql "\nCOMMIT;\n\n"
    }

    return $sql
}


# ############################ nextPage
# Creates page heading and resets line count
# @author LAq
# @param none
# @return page heading
proc nextPage {} {
    global sdgInfo

    set sdgInfo(page_count) [expr $sdgInfo(page_count) + 1]
    set sdgInfo(line_count) 4
    set report              ""

    lappend report "\t\t\t\t\tEXL Healthcare System Data Difference Report"
    lappend report "\t\t\t\t\t$sdgInfo(date_stamp)"
    lappend report "\t\t\t\t\tPage $sdgInfo(page_count)"

    return [join $report \n]
}


# ############################ _DEBUG_SDG_START
# If debug is set, turns on debug log file
# @author LAQ
# @param none
# @return none
proc _DEBUG_SDG_START {} {
    global sdgInfo

    if {![info exists sdgInfo(_SDG_DEBUG)]} {
        set sdgInfo(_SDG_DEBUG) "false"
    }

    if {$sdgInfo(_SDG_DEBUG) == "true"} {
        set sdgInfo(_debug_out_file) "_SDG_DEBUG_OUT.out"
        set sdgInfo(_debug_out) [open $sdgInfo(_debug_out_file) a]
        _SDG_PUTT "#++++++++++++++++++++++++++++++++++++++++#\n"
        _SDG_PUTT "Starting DEBUG [SysDataGen.version].[SysDataGen.revision]"
        _SDG_PUTT "[clock format [clock seconds]]"
    }
}


# ############################ _SDG_PUTT
# If debug is set, logs to file and sdout
# @author LAQ
# @param message to output
# @return none
proc _SDG_PUTT {message} {
    global sdgInfo

    if {$sdgInfo(_SDG_DEBUG) == "true"} {
        puts $message
        puts $sdgInfo(_debug_out) $message

        flush $sdgInfo(_debug_out)
    }
}


# ############################ _DEBUG_SDG_END
# If debug is set, turns off debug log file
# @author LAQ
# @param none
# @return none
proc _DEBUG_SDG_END {} {
    global sdgInfo

    if {[info exists sdgInfo(_debug_out)]} {
        _SDG_PUTT "Ending DEBUG [SysDataGen.version].[SysDataGen.revision]"
        _SDG_PUTT "[clock format [clock seconds]]"
        _SDG_PUTT "#----------------------------------------#\n"
        close $sdgInfo(_debug_out)
    }
}



# ############################ checkSytemYN
# @author BCP
# @param search_key key columns for the table
# @param concat_cols columns for the table
# @param table name in which to search
# @param model_key value that makes up the key from the model file
# @return 1 if nothing is returned by the query, otherwise return a list which consists of 0, schema_keys, and schema_data
proc checkSystemYN {search_key concat_cols table_name model_key} {
    set temp_schema_keys ""
    set temp_schema_data ""
    set select_template    "select $search_key, $concat_cols
                            into :temp_schema_keys, :temp_schema_data
                            from $table_name
                            where $search_key = '$model_key'"
    catch {execsql $select_template} err
    if {$err == -1} {
        error "***ERROR***" " - There was an error running the followig SQL:\n$select_template"
    }
    if {$temp_schema_keys == ""} {
        return 1
    } else {
        return [list 0 $temp_schema_keys $temp_schema_data]
    }
}


# ############################ sysDataGen
# main procedure  - call directly when sourced, or via "MAIN loop"
# @author LAQ
# @param dbh database connection handle
# @param database name/server only
# @param modelDirectory directory of system data model files to validate schema against.
# @param {out_directory ""} directory to put output files (default is current directory)
# @param {AutoScript "no"} flag set if sourced by autoscript
# @param {ver_test "no"} flag set if bat file should be generated to run scripts to update schema
# @param {silent 0} flag to set if should run in silent mode.
# @return none
proc sysDataGen {dbh database modelDirectory {out_directory ""} {AutoScript "no"} {ver_test "no"} {silent 0}} {
    global sdgInfo modifiedTables

    _DEBUG_SDG_START
    set toolName "SysDataGen"
    set tool_version        [SysDataGen.version]
    set tool_revision       [SysDataGen.revision]
    set home                [pwd]
    set sdgInfo(line_count) 15
    set sdgInfo(page_count) 0
    set sdgInfo(database)   "$database"
    set page_count          1
    set commitAfterCount    50
    set sdgInfo(maxLines)   50
    set spaces              "                                        "
    set separater           "-  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -"
    set db_delimit          "!!!"
    set sdgInfo(db_delimit) $db_delimit
    set time_start [setStartTime SysDataGen]
    set time_stamp          [clock format $time_start -format "%m%d%H%M%S"]
    set date_stamp          [clock format $time_start -format "%B %d, %Y"]
    set sdgInfo(date_stamp) $date_stamp
    regexp {[0-9]+} $modelDirectory short_target
    set product             [getSchemaProduct $dbh]
    set prod_prefix         [getProductPrefix $product]

    # Create the output director
    set out_directory [makeDir $out_directory]
    set seq [getNextSequence sysDataDiffSeq]
    set outFile "sysDataDiff_$time_stamp\_$seq\.txt"
    updateInfo $toolName.OUTDIR $out_directory
    # open the log file
    puts "\n[getInfo HR]"
    set report [getReportFile $toolName [getInfo $toolName.OUTDIR] $outFile]
    fconfigure $report -encoding utf-8
    updateInfo $toolName.REPORT_HANDLE $report
    updateInfo default_channel $report
    printInitialHeader $toolName [$toolName.getDescription] [$toolName.version].[$toolName.revision]
    # Path to directory with NAME, VALUES, WHERE and sysdate files.
    if { [catch {set mod_ver [open "[file join [getInfo MODEL_FILES_DIRECTORY] $modelDirectory MODEL_VERSION]" r]} ] } {
        putt [p_runtimeError "The attempt to certify System Data has failed! \n\nThere is no MODEL_VERSION file in [file join [getInfo MODEL_FILES_DIRECTORY] $modelDirectory].\nImmediately contact [getInfo SupportContact]"]
    }

    # get the model version
    gets $mod_ver version
    close $mod_ver

    set version     [string trim $version]
    set shs_version [string trim [getSchemaVersion $dbh]]
    putt "Schema version: $shs_version"
    putt "Model version:  $version"

    if {"$shs_version" != "$version"} {
        putt "schema version and model version are different."
        putt "Cannot validate between different versions."
        return 1
    }

   if {$prod_prefix == ""} {
        set c_row [getCurrentDriverRow "AutoConversion.txt" $version ]
        set prod_prefix [lindex $c_row 3]
        set product [getProductName $prod_prefix]
    }

    # TODO: i don't believe CR uses the mfa this way
    if {$prod_prefix != "CF" && $prod_prefix != "MXT"} {
        set SQL_Statement  "select  mfa_code
                            into    :valid_mfa_lst
                            from    mfa_menu_functional_area"
        execsql use $dbh $SQL_Statement SQL_Error
    }

    # get the relevant system data model files
    # open NAMES file.
    if {[catch {glob -directory "[file join [getInfo MODEL_FILES_DIRECTORY] $modelDirectory]" *NAMES*.txt} names_file] || [catch {
            set names_file [string map {\{ "" \} ""} $names_file]
            set names [open $names_file r]
            fconfigure $names -encoding utf-8
        } err ]
    } {
        putt [p_runtimeError  "The attempt to certify System Data has failed!\nThere is no NAMES file in $modelDirectory. \n[getInfo SupportContact]" ]
        return 1
    }

    # open VALUES file.
    if {[catch {glob -directory "[file join [getInfo MODEL_FILES_DIRECTORY] $modelDirectory]" *VALUES*.txt} values_file]  || [catch {
            set values_file [string map {\{ "" \} ""} $values_file]
            set values [open $values_file r]
            fconfigure $values -encoding utf-8
        }  err ]
    } {
        putt [p_runtimeError  "The attempt to certify System Data has failed!\nThere is no VALUES file in $modelDirectory. \n[getInfo SupportContact]" ]
        return 1
    }

    # Check for presence of WHERE file.
    set where_table_lst     ""
    set where_clause_lst    ""

    if {[catch {glob -directory "[file join [getInfo MODEL_FILES_DIRECTORY] $modelDirectory]" *WHERE*.txt} where_file] || [catch {
            set where_file [string map {\{ "" \} ""} $where_file]
            set where_source [open $where_file r]
            fconfigure $where_source -encoding utf-8
        }  err ]
    } {
        putt [p_runtimeError  "The attempt to certify System Data has failed!\nThere is no WHERE file in $modelDirectory. \n[getInfo SupportContact]" ]
        return 1
    } else {
        # Set up WHERE tables and WHERE names.
        set where_lst [getWhereClauses $where_source]
        set where_table_lst [lindex $where_lst 0]
        set where_clause_lst [lindex $where_lst 1]
        close $where_source
    }

    gets $names name_header
    gets $values value_header

    if {[string range $name_header 0 15] != [string range $value_header 0 15] } {
        putt [p_runtimeError  "The attempt to certify System Data has failed!\nHeader information in NAME and VALUE files inconsistent.\n[getInfo SupportContact]"]
        return -1
    }

    set model       [string range $names_file 0 1]
    set version_lst [split $version .]
    foreach point $version_lst {
        append pointless $point
    }
    set version [string trimleft [string trimright $version \}] \{]

    set out_directory_display_name  "[file tail $out_directory]"

    # open report & DML files.
    # write headers etc.
    putt "Preparing System Data Reports/Corrections Scripts for:"
    putt "    Database:                 $sdgInfo(database)"
    putt "    Model Data Directory:     $modelDirectory"
    putt "    Report/Scripts Directory: $out_directory_display_name"
    putt "[getInfo hr]\n"

    # logit "Setting session date format to DD-MON-YYYY"
    set SQL_Statement "alter session set nls_date_format = 'DD-MON-YYYY'"
    catch {execsql use $dbh $SQL_Statement {SQL_Error $SQL_Statement} }

    set seq [getNextSequence sysDataUpdateSeq]
    set DML [open [file join $out_directory "sysDataUpdate_$time_stamp\_$seq\.sql"] w]
    fconfigure $DML -encoding utf-8

    set seq [getNextSequence nonSysRowsSeq]
    set del_can [open [file join $out_directory "nonSysRows_$time_stamp\_$seq\.sql"] w]
    fconfigure $del_can -encoding utf-8

    set DTR_flag    N
    set del_spool   "$prod_prefix$pointless\_Deletes\_$time_stamp.lst "

    puts $del_can [deleteScriptHeader $names_file $values_file $where_file $del_spool]
    # logit "[nextPage]"
    #logit [reportHeader $names_file $values_file $where_file]

    set DML_Spool $prod_prefix$pointless\_Updates\_$time_stamp\.lst

    puts $DML [DMLheader $names_file $values_file $where_file $DML_Spool $AutoScript]
    set scriptname "sysDataUpdate_$time_stamp\.sql"
    set shs_insert "[getSHSinsert "$scriptname" UPDATE "Generated by SysDataGen.tcl version $tool_version, revision $tool_revision" Started ];"

    puts $DML $shs_insert
    puts $DML "COMMIT\;\n\n"

    regsub -all sysDataUpdate $shs_insert nonSysRows shs_del
    puts $del_can $shs_del
    puts $del_can "COMMIT\;\n\n"

    puts $DML "alter session set nls_date_format = 'DD-MON-YYYY'\;"
    puts $DML ""
    puts $DML ""

    # BEGIN processing data
    # the first entry in each of the value/data files will be the
    # table name that is the same as the table name in NAMES,
    # and is only there for testing for the next table entry.
    gets $values system_data
    gets $names info_lst

    set DELETETABLES        ""
    set INSERTTABLES        ""
    set UPDATETABLES        ""
    set MOVETABLES          ""
    set MAPTABLES           ""
    set CHANGEDTABLES       ""
    set UPDATES             ""
    set INSERTS             ""
    set NOCHANGETABLES      ""
    set DELETESTATEMENTS    ""
    set INSERTSTATEMENTS    ""
    set UPDATESTATEMENTS    ""
    set MOVESTATEMENTS      ""
    set MAPSTATMENTS        ""
    set DELETEVALUES        ""
    set INSERTVALUES        ""
    set UPDATEVALUES        ""
    set MOVEVALUES          ""
    set MAPVALUES           ""
    set DELETE_COUNT        0
    set modifiedTables      ""


    # Process the first entry in names table to check if the schema is CR or not (if it isn't CR then there will be no audit columns)

    set table_name          [lindex $info_lst 0]
    set table_prefix        [string range $table_name 0 2]
    set sql "select  column_name
            into    :auditcol
            from    user_tab_columns
            where   column_name = '$table_prefix\_CREATE_DATE'"
    execsql $sql

    if {$auditcol != {}} {
        set sdgInfo(auditColumns) "true"
    } else {
        set sdgInfo(auditColumns) "false"
    }

    ### Process each entry in the NAMES table
    ## We are letting the NAMES file drive the logic.
    ## For each new table in the NAMES file, a select template is build
    ## in order to query the db for each set of keys in the data, and
    ## an insert template is built for each row of data not in database.
    # older model files don't have TOR in model - check it separately
    # ---------------------------- main loop through tables names
    while { ! [eof $names] } {
        set table_name          [lindex $info_lst 0]
        set changes_flag        "N"
        set table_prefix        [string range $table_name 0 2]
        # now ignoring TOR, as dbcompare will update it - also need to ignore SCH SCD SCL entries.
        if {$table_name == "TOR_TABLE_ORDER"} {
            set break no
            while { (![eof $values]) && $break == "no"} {
                gets $values system_data
                if { [string range $system_data 0 1] == "->" || $system_data < "*" } {
                # break this while loop for the larger loop [eof names]
                    break
                }
            }
            gets $names info_lst
            continue
        }
        _SDG_PUTT "processing $table_name"

        # get the key names/ column names from the model file - they are separated by !
        set column_name_lst [split [lindex $info_lst 2] !]
        regsub -all ! [lindex $info_lst 1] , key_names
        set key_name_lst [split [lindex $info_lst 1] !]
        gets $names info_lst
        if {[string trim $table_name] == ""} {continue}
        # Check to make sure model files are valid - otherwise data might get mixed up- that would be BAD!
        if { [ string range $system_data 2 end] != $table_name } {
            set warning "Names and Values files not in sync ($table_name).\nSevere Error.\nProcessing will be terminated.\n[getInfo SupportContact]"
            puts $DML $warning
            close $DML
            setlog OFF $report
            set message "Error when processing SysDataGen.tcl! \n[getInfo SupportContact]\n$warning"
            if { $AutoScript == "yes" } {
                logit [p_runtimeError $message]
                error $message
            } else {
            #fix me
                putt [p_runtimeError "$message"]
                putt "exiting"
                return -1
            }
        }

        set search_key      [join $key_name_lst "||'$db_delimit'||"]
        set insert_template "([join $key_name_lst ","]"
        set concat_cols     [join $column_name_lst "||'$db_delimit'||"]

        if {[llength $column_name_lst] > 0} {
            append insert_template , [join $column_name_lst ","]
            set select_template    "select $search_key, $concat_cols
                                    into :schema_keys, :schema_data
                                    from $table_name "
            set select_templateA "select $search_key, $concat_cols
                                    into :schema_key, :schema_datum
                                    from $table_name "
            set select_templateB "select $search_key || '`'|| $concat_cols
                                    from $table_name "
        } else {
            set select_template    "select  $search_key
                                    into    :schema_keys
                                    from    $table_name "
            set schema_data ""
            set select_templateB    "select  $search_key
                                    from    $table_name "
        }

        set tindex          [lsearch $where_table_lst $table_name]
        set where_clause    [lindex $where_clause_lst $tindex]

        if {$tindex >= 0} {
            set select_template "$select_template where $where_clause"
        }

        if {[regexp "order by" $select_template] == 0} {
            append select_template " order by [join $key_name_lst ","]"
        }

        set n_names     [expr [llength $column_name_lst] + [llength $key_name_lst]]
        set n_col_names [llength $column_name_lst]

        if {$sdgInfo(auditColumns) == "true"} {
            append insert_template ", $table_prefix\_USR_UID_CREATED_BY, $table_prefix\_CREATE_DATE"
        }

        append insert_template "\") values (\""

        set system_data ""
        set model_key_list ""
        set model_key_value ""

        # Now we'll process all the values for this table,
        # continuing until a new table name ( ->) is encountered, at which point
        # the next entry in the NAMES file will be read in the outer loop.
        set new_key_lst     ""
        set break           "no"
        set model_data      ""
        set updates         ""
        set deletes         ""
        set moves           ""
        set maps            ""
        set mapPKs          ""
        set movePKs          ""
        set insertFlag      ""
        set systemYNData    ""
        set meta1 0
        set insertCount 0
        set updateCount 0
        set moveMapCount 0
        set moveRows ""
        set mapRows ""
        set moveVals    ""
        set mapVals    ""
        #_SDG_PUTT "select Template: $select_template"
        catch {execsql $select_template} err
        if {$err == -1} {
            error "***ERROR***" " - There was an error running the followig SQL:\n$select_template"
        }

        # read through each line of the values list for the table referenced in the loop above.
        # -> indicates the start of a new table's data

        while { ! [eof $values] && $break == "no"} {
            gets $values system_data
            if { [string range $system_data 0 1] == "->" || $system_data < "*" } {
                # break this while loop for the larger loop [eof names]
                break
            } else {
                # process the input from the values file
                set i_pound_sign    [string first "###" $system_data]
                if {$i_pound_sign < 0} { set i_pound_sign [string length $system_data]}
                    set model_key       [string range $system_data 0 [expr $i_pound_sign -1]]
                    set model_value     [string range $system_data [expr $i_pound_sign +3] end]
                lappend model_key_list $model_key
                lappend model_value_list $model_value
                # it's possible that the record does't exist because the system_yn flag is incorrect
                set insertFlag 0
                if {[lsearch $schema_keys $model_key] < 0} {
                    set insertFlag 1
                    if {[lsearch -glob $column_name_lst "*SYSTEM_YN"] >= 0} {
                        set systemYNData [checkSystemYN $search_key $concat_cols $table_name $model_key]
                        set insertFlag [lindex $systemYNData 0]
                        if {!$insertFlag} {
                            lappend schema_keys [lindex $systemYNData 1]
                            lappend schema_data [lindex $systemYNData 2]
                        }
                    }
                }
                set schema_key $model_key
                set schema_datum [lindex $schema_data [lsearch $schema_keys $schema_key]]
            # check the model list and determine if schema has value, and if so, if it matches
                set newsql ""
                if {$insertFlag} {
                    set newKey [cleanModelVals $model_key $db_delimit]
                    if {[llength $column_name_lst] == 0} {
                        set newVals ""
                    } else {
                        set newVals [cleanModelVals $model_value $db_delimit]
                    }
                    if {$n_names != [expr [llength $newKey] + [llength $newVals]] && ($newVals != {} && $column_name_lst != 0)} {
                        putt [p_runtimeError "SysDataGen.tcl did not complete successfully. Contact EXL Healthcare Support.  $key_name_lst:$column_name_lst nn $n_names [llength $newKey] + [llength $newVals]  t $table_name nk $newKey nv $newVals mv $model_value"]
                    }
                    # here check for possible unique constraints that match.  In that case, update uid value instead of insert.
                    set insertCheckList [checkUniqueRow $dbh $table_name $key_name_lst $column_name_lst "$newKey $newVals" $db_delimit $meta1]
                    set meta1 [lindex $insertCheckList 7] ;# save off to avoid requerying for metadata.
                    # straight insert of value
                    if {[lindex $insertCheckList 0] != ""} {
                        lappend new_key_lst $newKey
                        lappend model_data "$newKey $newVals"
                        incr insertCount
                        continue
                    }
                    # just change UID value
                    if {[lindex $insertCheckList 1] != ""} {
                        lappend moveRows  $newKey
                        lappend moveVals [lindex $insertCheckList 3]
                        set schema_key [lindex $insertCheckList 5]
                        lappend movePKs $schema_key
                        set newsql "$select_templateA where $key_name_lst = '$schema_key'"

                    }
                    # need to change uid and map fk tables to new uid.
                    if {[lindex $insertCheckList 2] != ""} {
                        lappend mapRows $newKey
                        lappend mapVals [lindex $insertCheckList 4]
                        set schema_key [lindex $insertCheckList 6]
                        lappend mapPKs $schema_key
                        set newsql "$select_templateA where $key_name_lst = '$schema_key'"
                    }
                    # for those items to be moved, get the current values to compare.
                    if {$newsql != ""} {
                        incr updateCount
                        incr moveMapCount
                        catch {execsql use $dbh "$newsql"} err
                    }
                }
                # value exists
                # check if the schema has the same data as the model data
                # - check the whole row first
                if {$schema_datum != $model_value} {
                    # some value is different
                    # lappend update_key_lst $model_key
                    set modelValues [cleanModelVals $model_value $db_delimit]
                    set schemaValues [cleanModelVals $schema_datum $db_delimit]
                    # captureDiffs will determine which columns have data that needs updating
                    if {[set diffs [captureDiffs $modelValues $schemaValues $column_name_lst]] != {}}     {
                        set modkey [cleanModelVals $model_key $db_delimit]
                        lappend updates [list $modkey $diffs]
                        if {$newsql == ""} {incr updateCount}
                    }
                }
            }
        } ; #end of search through model files for this table

        if {[expr $insertCount + $updateCount ] > 0} {
            puts $DML "/*=====================================\n  Processing Table $table_name\n  =====================================*/\n"
        }
        # process rows that need full inserts of data
        if {$insertCount > 0 } {
            set insertStatements    [doInserts $dbh $table_name $key_name_lst $column_name_lst $model_data]
                set disableStatements   [lindex $insertStatements 1]
                set enableStatements    [lindex $insertStatements 2]
                set insertStatements    [lindex $insertStatements 0]
                _SDG_PUTT "-- $table_name inserts --"
                puts $DML [join $disableStatements \n]\n
                puts $DML [outputWithCommits $insertStatements $commitAfterCount]
                puts $DML [join $enableStatements \n]\n
                keysToAdd $report $table_name $key_name_lst $new_key_lst
        }

        # process rows that have wrong PK values
        if {[llength $moveRows] > 0} {
            set moveStatments   [doMoves $table_name $key_name_lst $column_name_lst $model_data $moveRows $moveVals]
            puts $DML [outputWithCommits $moveStatments $commitAfterCount]
            keysToMove $report $table_name $key_name_lst $moveRows $movePKs
        }

        #process rows that have wrong PK values and need child table FKs to be mapped
        if {[llength $mapRows] > 0} {
            set mapStatements   [doMaps $dbh $table_name $key_name_lst $column_name_lst $model_data $mapRows $mapVals $mapPKs]
            # map statements built with commits in place
            puts $DML "$mapStatements\n"

            keysToMap $report $table_name $key_name_lst $mapRows $mapPKs
        }
        #process rows that need some values updated.
        if {[llength $updates] > 0} {
                # Process normal updates
                set updateStatements [doUpdates $table_name $updates $key_name_lst]
                puts $DML [outputWithCommits $updateStatements $commitAfterCount]
                keysToUpdate $report $table_name $key_name_lst $updates
        }

        # Now check for items to remove that met the "where" criteria in schema, but are not in model
        # ie DELETES
        set oldPKList [concat $movePKs $mapPKs]
        set modelKeyList [lsort $model_key_list]
        foreach schema_key $schema_keys {
            if {[set vindex [lsearch -sorted $modelKeyList $schema_key]] < 0} {
                if {[lsearch $oldPKList $schema_key] < 0} {
                    # lappend delete_key_lst $schema_key
                    lappend deletes "[cleanModelVals $schema_key $db_delimit]"
                    lappend badtable $table_name*del*$schema_key
                } else {
                    puts $del_can "--  $table_name key $schema_key will be moved, not deleted.  --"
                }
            }
        }
        set deleteCount 0
        if {[llength $deletes] > 0} {
            set deleteStatements [doDeletes $table_name $deletes $key_name_lst $where_clause]
            incr deleteCount [llength $deletes]
            puts $del_can [outputWithCommits $deleteStatements $commitAfterCount]
        }

        if {[expr $insertCount + $updateCount + $deleteCount] > 0} {
            lappend KEYCOLUMNS      $key_name_lst
            lappend CHANGEDTABLES   $table_name
            lappend UPDATES         $updateCount
            lappend INSERTS         $insertCount
            lappend DELETES         $deleteCount
            incr DELETE_COUNT       $deleteCount
            # keysToMapCollision $report $table_name $key_name_lst
        } else {
            lappend NOCHANGETABLES $table_name
        }
        # end of processing table XXX
    }; # end all tables

    # ##################################### end data processing
    close $names
    close $values

    set shs_insert "[getSHSupdate $scriptname ""];"

    puts $DML ""
    puts $DML $shs_insert
    puts $DML "commit\;"

    regsub -all sysDataUpdate $shs_insert nonSysRows shs_del

    puts $del_can $shs_del
    puts $del_can   "COMMIT\;"

    logit    "\n[nextPage]"
    logit    "\n\n   Table                         Inserts  Updates\n   -----                         -------  -------"
    puts $DML       "\n/* Table                         Inserts  Updates\n   -----                         -------  -------"

    set i_summary       0
    set data_certified  "yes"
    set INSERT_COUNT    0
    set UPDATE_COUNT    0

    if {[llength $CHANGEDTABLES] == 0} {
        set data_certified "yes"
    } else {
        set data_certified "no"
    }

    foreach table $CHANGEDTABLES updates $UPDATES inserts $INSERTS {
        set line_out [format "%-31s%7d%9d" $table $inserts $updates]

        puts $DML $line_out
        logit $line_out

        incr INSERT_COUNT $inserts
        incr UPDATE_COUNT $updates
    }

    if {[llength $NOCHANGETABLES] > 0} {
        logit    "\n\nNo Changes to [llength $NOCHANGETABLES] tables"
        puts $DML       "\n\nNo Changes to [llength $NOCHANGETABLES] tables"
    }

    puts $DML "\n*/"

    set time_end        [clock seconds]
    set total_seconds   [getDurationHMS [getStartTime SysDataGen]]
    set total_minutes   [lindex $total_seconds 1]
    set total_seconds   [lindex $total_seconds 2]

    # logit "\nRun Time was [prettyTime [hms $total_seconds]]"
    logit "\n * * * End of Data Comparison Report  * * *"

    puts $DML ""
    puts $DML "/*============================================================================"
    puts $DML "SysDataGen.tcl version $tool_version, revision $tool_revision built this script. "
    puts $DML "Run Time was [prettyTime [hms $total_seconds]]."
    puts $DML "============================================================================*/"
    puts $DML "spool off"
    puts $DML "exit"

    close $DML
    puts $del_can "spool off"
    puts $del_can "exit"

    close $del_can

    set statFile "[file join $out_directory "AutoStat.txt"]"

    if { $ver_test != "no" } {
        set SYSDATAGEN_STATUS   "$INSERT_COUNT $UPDATE_COUNT $DELETE_COUNT"
        set curr_date           [clock format [clock seconds] -format "%m/%d/%y"]
        set parms               "S $curr_date _ _$short_target"
        set parms               [lreplace $parms 1 1 $curr_date]

        if { $DELETE_COUNT == 0 && $data_certified == "yes" } {
            set parms [lreplace $parms 0 0 A]
        }

        set stat [open $statFile w 77777]

        puts $stat $parms

        if {$DELETE_COUNT != 0 } {
            puts $stat "nonSysRows_$time_stamp\_[getInfo nonSysRowsSeq].sql"
        }

        if { $data_certified == "no" } {
            puts $stat "sysDataUpdate_$time_stamp\_[getInfo sysDataUpdateSeq].sql"
        }

        close $stat
    }

    putt ""
    putt [getInfo HR]
    putt "SysDataGen.tcl version $tool_version, revision $tool_revision"
    putt "has generated the following: "
    putt ""
    putt "  A comparison report listing system data differences"
    putt "      sysDataDiff_$time_stamp\_[getInfo sysDataDiffSeq].txt"
    putt "  A script to insert and update system data records"
    putt "      sysDataUpdate_$time_stamp\_[getInfo sysDataUpdateSeq].sql"
    putt "  A script to list and delete obsolete system data records"
    putt "      nonSysRows_$time_stamp\_[getInfo nonSysRowsSeq].sql"
    puts " in directory\n$out_directory"
    putt ""
    putt "  Delete count: $DELETE_COUNT"
    putt "  Insert count: $INSERT_COUNT"
    putt "  Update count: $UPDATE_COUNT"
    putt ""
    if {[expr $DELETE_COUNT + $INSERT_COUNT + $UPDATE_COUNT] == 0} {
        set STATUS "PASS"
    } elseif {[expr $INSERT_COUNT + $UPDATE_COUNT] == 0} {
        set STATUS "WARN"
    } else {
        set STATUS "FAIL"
    }
    set duration [getDuration [getStartTime SysDataGen]]
    putt      "Run Time was [prettyTime [hms $duration]]."
    logit       "END: [clock format [clock seconds] -format "[getInfo dateFormat] [getInfo timeFormat]"]"
    putt "[getInfo HR]"
    putt "RESULTS: [expr $INSERT_COUNT + $UPDATE_COUNT]"
    putt       "STATUS: $STATUS"
    unsetInfo   "SysDataGen.START"
    setlog OFF [getInfo SysDataGen.REPORT_HANDLE]
    unsetInfo   SysDataGen*

    # this will output to autoscript log
    if {[getInfo AutoScript.REPORT_HANDLE] != ""} {
        puts [getInfo AutoScript.REPORT_HANDLE] "SysDataGen.tcl version $tool_version, revision $tool_revision completed."
    }
    # clean up bat files
    delete_like "sdg*.bat"

    _DEBUG_SDG_END
    return [list $INSERT_COUNT $UPDATE_COUNT $DELETE_COUNT $statFile]
}
proc SysDataGen.getDescription {} {
    return "Script to validate a schema's system data against system data model files
and create DML scripts to correct the data, if necessary."
}
# ############################ gsd_usage
# outputs usage info when input is invalid
# @author RE
# @return none
proc gsd_usage {} {
    puts ""
    puts "[SysDataGen.getDescription]"
    puts ""
    puts "USAGE: mtclsh SysDataGen.tcl <System Data Model Files directory> <Target database connect string> \[Report/DML directory\] \[SILENT\]"
    puts ""
    puts "SILENT:"
    puts "Use SILENT as the last parameter if you wish avoid requests for user input."
    puts "The result is that SysDataGen will most likely terminate without user \nacknowledgement of an error."
    puts ""
    puts "EXAMPLE: mtclsh SysDataGen.tcl mod45 siteuser/sitepass@siteserver v45_prod SILENT"
    puts ""
}


#==============================================================================#
#   Main Execution
#==============================================================================#
# @param argv 0 database connection string
# @param argv 1 autoconversion text file
# @param argv 2 "silent" default ""
if {[info exists argv0] && [string tolower [file tail $argv0] ] == "sysdatagen.tcl"} {
    set silent [lindex $argv end]
    if {[regexp -nocase "silent" $silent]} {
        set silent 1
        incr argc -1
        puts "Running in silent mode, user input will be suppressed."
        catch {puts "Running in silent mode, user input will be suppressed."}
    } else {
        set silent 0
    }

    if { $argc < 2 } {
        puts [p_runtimeError "Not enough Arguments"]
        gsd_usage
        exit -1
    }
    set database [lindex $argv 1]
    set display [getDisplayConnection $database]

    setInfo SDG.silent $silent
    setInfo CONNECTION_STRING $database
    if { [catch {getLogonHandle $database} sdgdbh ] }  {
        puts [p_runtimeError "Cannot log onto $database"]
        exit -1
    }
    set validSHS [validateSHS $sdgdbh ]
    if {$validSHS != ""} {
        puts "The following script did not complete: $validSHS"
        putt "Contact the EXL Healthcare Support Department for assistance: "
        putt [getInfo SupportContact]
        exit 1
    }
    set modelDirectory [lindex $argv 0]
    if {[string tolower [lindex $argv 2]] != "silent"} {
        set outputdir [lindex $argv 2]
    } else {
        set outputdir "."
    }

    setInfo SDG.outDir $outputdir

    if {[catch {sysDataGen $sdgdbh $display  $modelDirectory $outputdir "no" "no"} err]} {
        putt $err\n$::errorInfo
    }

}